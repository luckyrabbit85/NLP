{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec3f0afa",
   "metadata": {},
   "source": [
    "## Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36636584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10dadca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'ARMAGEDDON.txt'\n",
    "\n",
    "file = open(fileName, \"r\", encoding = \"UTF-8\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f291dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f5fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "sentences = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc85197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.tokenize.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c5bb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_pos = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03974f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba66afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['leaf', 'leaves', 'booking', 'writing', 'completed', 'stemming', 'skies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "559d5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc76251",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53f1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9880510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92fb02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.tokenize.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b28f08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = FreqDist(word.lower() for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd62ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 23, 'and': 15, '.': 14, ',': 13, 'of': 10, 'a': 9, 'they': 7, 'to': 7, 'alan': 6, 'he': 6, ...})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6854a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_frequencies = [(word, freq_dist[word]) for word in freq_dist.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f99e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = sorted(words_with_frequencies, key=lambda tup:tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9c5c0",
   "metadata": {},
   "source": [
    "## Using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2eda16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab4ca7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'ARMAGEDDON.txt'\n",
    "\n",
    "file = open(fileName, \"r\", encoding = \"UTF-8\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a2ae01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "265b576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "sentences = [sentence.text for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08d7ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ffb2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [token.pos_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "319be44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pos_tuples = list(zip(words, pos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
