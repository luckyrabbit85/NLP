# NLP

# Understanding Transformers

Here I'have tried to explain the Transformer architecture used in the paper 
[Attention is all you need](https://arxiv.org/abs/1706.03762) 

# Fine Tuning BERT for Sequence Classification

# Machine Translation with Transformers

http://statmt.org/europarl/v10/training/
https://github.com/google/trax
